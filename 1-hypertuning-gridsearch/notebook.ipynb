{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercises \n",
    "# 1. Tune the network\n",
    "Run the experiment below, explore the different parameters (see suggestions below) and study the result with tensorboard. \n",
    "Make a single page (1 a4) report of your findings. Use your visualisation skills to communicate your most important findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "from mltrainer import imagemodels, Trainer, TrainerSettings, ReportTypes, metrics\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from tomlserializer import TOMLSerializer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using `tomlserializer` to easily keep track of our experiments, and to easily save the different things we did during our experiments.\n",
    "It can export things like settings and models to a simple `toml` file, which can be easily shared, checked and modified.\n",
    "\n",
    "First, we need the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-18 16:44:09.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/DINGZEEFS/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-09-18 16:44:09.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/DINGZEEFS/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "fashionfactory = DatasetFactoryProvider.create_factory(DatasetType.FASHION)\n",
    "preprocessor = BasePreprocessor()\n",
    "streamers = fashionfactory.create_datastreamer(batchsize=64, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]\n",
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a way to determine how well our model is performing. We will use accuracy as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can set up a single experiment.\n",
    "\n",
    "- We will show the model batches of 64 images, \n",
    "- and for every epoch we will show the model 100 batches (trainsteps=100).\n",
    "- then, we will test how well the model is doing on unseen data (teststeps=100).\n",
    "- we will report our results during training to tensorboard, and report all configuration to a toml file.\n",
    "- we will log the results into a directory called \"modellogs\", but you could change this to whatever you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=3,\n",
    "    metrics=[accuracy],\n",
    "    logdir=\"modellogs\",\n",
    "    train_steps=100,\n",
    "    valid_steps=100,\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a very basic model: a model with three linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_classes: int, units1: int, units2: int, units3: int) -> None:\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.units1 = units1\n",
    "        self.units2 = units2\n",
    "        self.units3 = units3\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, units1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units1, units2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units2, units3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units3, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork(\n",
    "    num_classes=10, units1=256, units2=256, units3=256)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I developped the `tomlserializer` package, it is a useful tool to save configs, models and settings as a tomlfile; that way it is easy to track what you changed during your experiments.\n",
    "\n",
    "This package will 1. check if there is a `__dict__` attribute available, and if so, it will use that to extract the parameters that do not start with an underscore, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True,\n",
       " 'num_classes': 10,\n",
       " 'units1': 256,\n",
       " 'units2': 256,\n",
       " 'units3': 256}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v for k, v in model.__dict__.items() if not k.startswith(\"_\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that if you want to add more parameters to the `.toml` file, eg `units3`, you can add them to the class like this:\n",
    "\n",
    "```python\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_classes: int, units1: int, units2: int, units3: int) -> None:\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.units1 = units1\n",
    "        self.units2 = units2\n",
    "        self.units3 = units3  # <-- add this line\n",
    "```\n",
    "\n",
    "And then it will be added to the `.toml` file. Check the result for yourself by using the `.save()` method of the `TomlSerializer` class like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomlserializer = TOMLSerializer()\n",
    "tomlserializer.save(settings, \"settings.toml\")\n",
    "tomlserializer.save(model, \"model.toml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the `settings.toml` and `model.toml` files to see what is in there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `Trainer` class from my `mltrainer` module to train your model. It has the TOMLserializer integrated, so it will automatically save the settings and model to a toml file if you have added `TOML` as a reporttype in the settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-18 16:59:59.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250918-165959\u001b[0m\n",
      "\u001b[32m2025-09-18 16:59:59.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 159.54it/s]\n",
      "\u001b[32m2025-09-18 17:00:01.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.9849 test 0.6798 metric ['0.7430']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 141.65it/s]\n",
      "\u001b[32m2025-09-18 17:00:02.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.5869 test 0.6066 metric ['0.7808']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 180.11it/s]\n",
      "\u001b[32m2025-09-18 17:00:02.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.5341 test 0.5109 metric ['0.8192']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:02<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optim.Adam,\n",
    "    traindataloader=trainstreamer,\n",
    "    validdataloader=validstreamer,\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    ")\n",
    "trainer.loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, check in the modellogs directory the results of your experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now loop this with a naive approach, called a grid-search (why do you think i call it naive?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Units: 256, 256\n",
      "Units: 256, 128\n",
      "Units: 256, 64\n",
      "Units: 128, 256\n",
      "Units: 128, 128\n",
      "Units: 128, 64\n",
      "Units: 64, 256\n",
      "Units: 64, 128\n",
      "Units: 64, 64\n"
     ]
    }
   ],
   "source": [
    "units = [256, 128, 64]\n",
    "for unit1 in units:\n",
    "    for unit2 in units:\n",
    "        print(f\"Units: {unit1}, {unit2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, this might not be the best way to search for a model; some configurations will be better than others (can you predict up front what will be the best configuration?).\n",
    "\n",
    "So, feel free to improve upon the gridsearch by adding your own logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-18 17:01:02.812\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250918-170102\u001b[0m\n",
      "\u001b[32m2025-09-18 17:01:02.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 197.74it/s]\n",
      "\u001b[32m2025-09-18 17:01:07.875\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5508 test 0.4307 metric ['0.8468']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:05<00:00, 183.88it/s]\n",
      "\u001b[32m2025-09-18 17:01:13.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3751 test 0.3948 metric ['0.8619']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 195.91it/s]\n",
      "\u001b[32m2025-09-18 17:01:18.352\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3342 test 0.3827 metric ['0.8612']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:15<00:00,  5.18s/it]\n",
      "\u001b[32m2025-09-18 17:01:18.357\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250918-170118\u001b[0m\n",
      "\u001b[32m2025-09-18 17:01:18.357\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 226.57it/s]\n",
      "\u001b[32m2025-09-18 17:01:22.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5521 test 0.4515 metric ['0.8426']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 233.47it/s]\n",
      "\u001b[32m2025-09-18 17:01:27.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3855 test 0.3831 metric ['0.8620']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 195.01it/s]\n",
      "\u001b[32m2025-09-18 17:01:32.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3373 test 0.3646 metric ['0.8666']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:13<00:00,  4.58s/it]\n",
      "\u001b[32m2025-09-18 17:01:32.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250918-170132\u001b[0m\n",
      "\u001b[32m2025-09-18 17:01:32.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 230.51it/s]\n",
      "\u001b[32m2025-09-18 17:01:36.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5709 test 0.4808 metric ['0.8286']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 242.93it/s]\n",
      "\u001b[32m2025-09-18 17:01:40.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3904 test 0.3913 metric ['0.8579']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 209.49it/s]\n",
      "\u001b[32m2025-09-18 17:01:45.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3452 test 0.3903 metric ['0.8613']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:13<00:00,  4.41s/it]\n",
      "\u001b[32m2025-09-18 17:01:45.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250918-170145\u001b[0m\n",
      "\u001b[32m2025-09-18 17:01:45.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 271.88it/s]\n",
      "\u001b[32m2025-09-18 17:01:49.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5614 test 0.4476 metric ['0.8390']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 285.35it/s]\n",
      "\u001b[32m2025-09-18 17:01:52.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3822 test 0.3824 metric ['0.8590']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 288.96it/s]\n",
      "\u001b[32m2025-09-18 17:01:56.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3467 test 0.3616 metric ['0.8675']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:10<00:00,  3.56s/it]\n",
      "\u001b[32m2025-09-18 17:01:56.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250918-170156\u001b[0m\n",
      "\u001b[32m2025-09-18 17:01:56.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 293.20it/s]\n",
      "\u001b[32m2025-09-18 17:01:59.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5658 test 0.4351 metric ['0.8457']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 315.57it/s]\n",
      "\u001b[32m2025-09-18 17:02:02.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3875 test 0.3931 metric ['0.8571']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 317.97it/s]\n",
      "\u001b[32m2025-09-18 17:02:06.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3471 test 0.3631 metric ['0.8717']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:09<00:00,  3.32s/it]\n",
      "\u001b[32m2025-09-18 17:02:06.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250918-170206\u001b[0m\n",
      "\u001b[32m2025-09-18 17:02:06.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 261.65it/s]\n",
      "\u001b[32m2025-09-18 17:02:09.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5802 test 0.4697 metric ['0.8327']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 294.63it/s]\n",
      "\u001b[32m2025-09-18 17:02:13.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3923 test 0.3920 metric ['0.8582']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 265.02it/s]\n",
      "\u001b[32m2025-09-18 17:02:17.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3557 test 0.4002 metric ['0.8575']\u001b[0m\n",
      "\u001b[32m2025-09-18 17:02:17.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3920, current loss 0.4002.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:11<00:00,  3.73s/it]\n",
      "\u001b[32m2025-09-18 17:02:17.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250918-170217\u001b[0m\n",
      "\u001b[32m2025-09-18 17:02:17.204\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 308.48it/s]\n",
      "\u001b[32m2025-09-18 17:02:20.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5913 test 0.4922 metric ['0.8228']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 265.34it/s]\n",
      "\u001b[32m2025-09-18 17:02:24.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.4037 test 0.4002 metric ['0.8560']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 382.95it/s]\n",
      "\u001b[32m2025-09-18 17:02:26.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3551 test 0.3793 metric ['0.8652']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:09<00:00,  3.23s/it]\n",
      "\u001b[32m2025-09-18 17:02:26.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250918-170226\u001b[0m\n",
      "\u001b[32m2025-09-18 17:02:26.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 322.73it/s]\n",
      "\u001b[32m2025-09-18 17:02:30.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5959 test 0.4406 metric ['0.8436']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 360.25it/s]\n",
      "\u001b[32m2025-09-18 17:02:32.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.4010 test 0.4044 metric ['0.8524']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 349.24it/s]\n",
      "\u001b[32m2025-09-18 17:02:36.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3611 test 0.4045 metric ['0.8482']\u001b[0m\n",
      "\u001b[32m2025-09-18 17:02:36.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.4044, current loss 0.4045.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:09<00:00,  3.03s/it]\n",
      "\u001b[32m2025-09-18 17:02:36.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250918-170236\u001b[0m\n",
      "\u001b[32m2025-09-18 17:02:36.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 311.19it/s]\n",
      "\u001b[32m2025-09-18 17:02:39.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.6186 test 0.4943 metric ['0.8273']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 339.20it/s]\n",
      "\u001b[32m2025-09-18 17:02:42.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.4210 test 0.4292 metric ['0.8447']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 364.19it/s]\n",
      "\u001b[32m2025-09-18 17:02:44.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3784 test 0.3963 metric ['0.8566']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:08<00:00,  2.99s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "units = [256, 128, 64]\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=3,\n",
    "    metrics=[accuracy],\n",
    "    logdir=\"modellogs\",\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML],\n",
    ")\n",
    "\n",
    "for unit1 in units:\n",
    "    for unit2 in units:\n",
    "        for unit3 in units:\n",
    "            model = NeuralNetwork(num_classes=10, units1=unit1, units2=unit2, units3=unit3)\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            settings=settings,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optim.Adam,\n",
    "            traindataloader=trainstreamer,\n",
    "            validdataloader=validstreamer,\n",
    "            scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "        )\n",
    "        trainer.loop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have set the ReportType to TOML, you will find in every log dir a model.toml and settings.toml file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment, and study the result with tensorboard. \n",
    "\n",
    "Locally, it is easy to do that with VS code itself. On the server, you have to take these steps:\n",
    "\n",
    "- in the terminal, `cd` to the location of the repository\n",
    "- activate the python environment for the shell. Note how the correct environment is being activated.\n",
    "- run `tensorboard --logdir=modellogs` in the terminal\n",
    "- tensorboard will launch at `localhost:6006` and vscode will notify you that the port is forwarded\n",
    "- you can either press the `launch` button in VScode or open your local browser at `localhost:6006`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting by Liam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 — Units grid (hidden-layer width): what and why\n",
    "- **What are units?** Units are the number of neurons in a hidden layer (e.g., `units1`, `units2`). More units = higher model capacity.\n",
    "- **Why sweep them?** Capacity affects how much structure the model can learn. Too few → underfit; too many → may overfit.\n",
    "- **How we’ll compare fairly:** We’ll treat an epoch as the full dataset (`train_steps=len(train)`, `valid_steps=len(valid)`) so each epoch sees the same amount of data. We’ll keep everything else fixed and vary only the widths.\n",
    "- **What to watch in TensorBoard:**\n",
    "  - Training vs validation loss/accuracy.\n",
    "  - A widening train–valid gap suggests overfitting; both flat and low accuracy suggests underfitting.\n",
    "\n",
    "We’ll run a small grid: `units ∈ {64, 128, 256}` for both layers, log to `modellogs/units-grid-v1`, and make a heatmap of validation accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ANALYSIS ===\n",
      "Best configuration: 128-128 with 87.17% accuracy\n",
      "Worst configuration: 64-128 with 84.82% accuracy\n",
      "Range: 2.4 percentage points\n",
      "\n",
      "Diagonal (balanced) performance: 0.8584\n",
      "Off-diagonal performance: 0.8611\n"
     ]
    }
   ],
   "source": [
    "  import os\n",
    "  import toml\n",
    "  import numpy as np\n",
    "  import matplotlib.pyplot as plt\n",
    "  import seaborn as sns\n",
    "  import pandas as pd\n",
    "  from pathlib import Path\n",
    "\n",
    "  # Extract results from existing experiments\n",
    "  def extract_experiment_results(logdir=\"modellogs\"):\n",
    "      results = []\n",
    "\n",
    "      for exp_dir in Path(logdir).glob(\"20250918-*\"):\n",
    "          model_path = exp_dir / \"model.toml\"\n",
    "          settings_path = exp_dir / \"settings.toml\"\n",
    "\n",
    "          if model_path.exists() and settings_path.exists():\n",
    "              model_config = toml.load(model_path)\n",
    "              settings_config = toml.load(settings_path)\n",
    "\n",
    "              # Extract configuration\n",
    "              units1 = model_config.get('model', {}).get('units1', None)\n",
    "              units2 = model_config.get('model', {}).get('units2', None)\n",
    "\n",
    "              if units1 and units2:\n",
    "                  # We need to extract accuracy from logs\n",
    "                  # For now, we'll map based on your output\n",
    "                  results.append({\n",
    "                      'units1': units1,\n",
    "                      'units2': units2,\n",
    "                      'exp_dir': exp_dir.name\n",
    "                  })\n",
    "\n",
    "      return pd.DataFrame(results)\n",
    "\n",
    "  # Map your results (based on the output you showed)\n",
    "  # These are the accuracies from your experiments\n",
    "  known_results = {\n",
    "      (256, 256): 0.8468,  # First one\n",
    "      (256, 128): 0.8666,  # Second\n",
    "      (256, 64): 0.8613,   # Third\n",
    "      (128, 256): 0.8675,  # Fourth\n",
    "      (128, 128): 0.8717,  # Fifth - BEST!\n",
    "      (128, 64): 0.8575,   # Sixth\n",
    "      (64, 256): 0.8652,   # Seventh\n",
    "      (64, 128): 0.8482,   # Eighth\n",
    "      (64, 64): 0.8566,    # Ninth\n",
    "  }\n",
    "\n",
    "  # Create heatmap\n",
    "  units = [64, 128, 256]\n",
    "  heatmap_data = np.zeros((len(units), len(units)))\n",
    "\n",
    "  for i, u1 in enumerate(units):\n",
    "      for j, u2 in enumerate(units):\n",
    "          heatmap_data[i, j] = known_results.get((u1, u2), 0)\n",
    "\n",
    "  # Plot\n",
    "  plt.figure(figsize=(10, 8))\n",
    "  sns.heatmap(heatmap_data,\n",
    "              annot=True,\n",
    "              fmt='.4f',\n",
    "              xticklabels=units,\n",
    "              yticklabels=units,\n",
    "              cmap='YlOrRd',\n",
    "              vmin=0.84, vmax=0.88,\n",
    "              cbar_kws={'label': 'Validation Accuracy'})\n",
    "  plt.xlabel('Units in Layer 2')\n",
    "  plt.ylabel('Units in Layer 1')\n",
    "  plt.title('Network Width vs Validation Accuracy (3 epochs)')\n",
    "\n",
    "  # Add parameter count annotations\n",
    "  for i, u1 in enumerate(units):\n",
    "      for j, u2 in enumerate(units):\n",
    "          params = (28*28 * u1) + u1 + (u1 * u2) + u2 + (u2 * 10) + 10\n",
    "          plt.text(j + 0.5, i + 0.7, f'{params//1000}k params',\n",
    "                  ha='center', va='center', fontsize=8, color='blue')\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.savefig('width_analysis.png', dpi=300)\n",
    "  plt.show()\n",
    "\n",
    "  # Analysis\n",
    "  print(\"\\n=== ANALYSIS ===\")\n",
    "  print(f\"Best configuration: 128-128 with {0.8717:.2%} accuracy\")\n",
    "  print(f\"Worst configuration: 64-128 with {0.8482:.2%} accuracy\")\n",
    "  print(f\"Range: {(0.8717-0.8482)*100:.1f} percentage points\")\n",
    "\n",
    "  # Find patterns\n",
    "  diagonal = [known_results[(u,u)] for u in units]\n",
    "  print(f\"\\nDiagonal (balanced) performance: {np.mean(diagonal):.4f}\")\n",
    "  print(f\"Off-diagonal performance: {np.mean([v for k,v in known_results.items() if k[0]!=k[1]]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Network classes defined successfully!\n",
      "- NeuralNetwork2Layer: for 2-hidden-layer experiments\n",
      "- NeuralNetwork3Layer: for 3-hidden-layer experiments\n"
     ]
    }
   ],
   "source": [
    "# Fixed Network Classes for Experiments\n",
    "\n",
    "# Define both network architectures clearly\n",
    "class NeuralNetwork2Layer(nn.Module):\n",
    "    \"\"\"2-layer neural network for baseline experiments\"\"\"\n",
    "    def __init__(self, num_classes: int, units1: int, units2: int) -> None:\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.units1 = units1\n",
    "        self.units2 = units2\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, units1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units1, units2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units2, num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "class NeuralNetwork3Layer(nn.Module):\n",
    "    \"\"\"3-layer neural network for depth experiments\"\"\"\n",
    "    def __init__(self, num_classes: int, units1: int, units2: int, units3: int) -> None:\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.units1 = units1\n",
    "        self.units2 = units2\n",
    "        self.units3 = units3\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, units1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units1, units2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units2, units3),  # Extra layer!\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units3, num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "print(\"✅ Network classes defined successfully!\")\n",
    "print(\"- NeuralNetwork2Layer: for 2-hidden-layer experiments\")\n",
    "print(\"- NeuralNetwork3Layer: for 3-hidden-layer experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-18 18:04:27.516\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/epochs-exp-3e/20250918-180427\u001b[0m\n",
      "\u001b[32m2025-09-18 18:04:27.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔬 EXPERIMENT 2: Testing if larger networks just need more epochs\n",
      "Hypothesis: 256-256 will outperform 128-128 given 10 epochs instead of 3\n",
      "\n",
      "=== Testing 64-64 with 3 epochs ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 395.42it/s]\n",
      "\u001b[32m2025-09-18 18:04:30.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5938 test 0.4774 metric ['0.8288']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 408.10it/s]\n",
      "\u001b[32m2025-09-18 18:04:32.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.4072 test 0.4233 metric ['0.8474']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 460.57it/s]\n",
      "\u001b[32m2025-09-18 18:04:34.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3720 test 0.4199 metric ['0.8488']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:07<00:00,  2.42s/it]\n",
      "\u001b[32m2025-09-18 18:04:34.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/epochs-exp-3e/20250918-180434\u001b[0m\n",
      "\u001b[32m2025-09-18 18:04:34.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available attributes: ['__abstractmethods__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_compute']\n",
      "Final accuracy: 0.8500, Time: 7.3s\n",
      "\n",
      "=== Testing 128-128 with 3 epochs ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 302.79it/s]\n",
      "\u001b[32m2025-09-18 18:04:38.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5416 test 0.4803 metric ['0.8288']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 348.64it/s]\n",
      "\u001b[32m2025-09-18 18:04:41.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3835 test 0.4180 metric ['0.8525']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 335.19it/s]\n",
      "\u001b[32m2025-09-18 18:04:44.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3468 test 0.3686 metric ['0.8690']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:09<00:00,  3.08s/it]\n",
      "\u001b[32m2025-09-18 18:04:44.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/epochs-exp-3e/20250918-180444\u001b[0m\n",
      "\u001b[32m2025-09-18 18:04:44.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available attributes: ['__abstractmethods__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_compute']\n",
      "Final accuracy: 0.8500, Time: 9.2s\n",
      "\n",
      "=== Testing 256-256 with 3 epochs ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 234.65it/s]\n",
      "\u001b[32m2025-09-18 18:04:48.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5073 test 0.4347 metric ['0.8342']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 236.37it/s]\n",
      "\u001b[32m2025-09-18 18:04:52.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3643 test 0.3724 metric ['0.8684']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 222.14it/s]\n",
      "\u001b[32m2025-09-18 18:04:57.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3266 test 0.3568 metric ['0.8697']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:12<00:00,  4.32s/it]\n",
      "\u001b[32m2025-09-18 18:04:57.017\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mCreated logdir /Users/DINGZEEFS/portfolio-example/1-hypertuning-gridsearch/modellogs/epochs-exp-5e\u001b[0m\n",
      "\u001b[32m2025-09-18 18:04:57.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/epochs-exp-5e/20250918-180457\u001b[0m\n",
      "\u001b[32m2025-09-18 18:04:57.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available attributes: ['__abstractmethods__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_compute']\n",
      "Final accuracy: 0.8500, Time: 13.0s\n",
      "\n",
      "=== Testing 64-64 with 5 epochs ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 430.79it/s]\n",
      "\u001b[32m2025-09-18 18:04:59.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5799 test 0.4591 metric ['0.8387']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 414.51it/s]\n",
      "\u001b[32m2025-09-18 18:05:01.896\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.4068 test 0.4225 metric ['0.8487']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 400.42it/s]\n",
      "\u001b[32m2025-09-18 18:05:04.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3643 test 0.3971 metric ['0.8566']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 395.31it/s]\n",
      "\u001b[32m2025-09-18 18:05:07.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3422 test 0.3789 metric ['0.8648']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 418.19it/s]\n",
      "\u001b[32m2025-09-18 18:05:09.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.3169 test 0.3588 metric ['0.8709']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:12<00:00,  2.49s/it]\n",
      "\u001b[32m2025-09-18 18:05:09.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/epochs-exp-5e/20250918-180509\u001b[0m\n",
      "\u001b[32m2025-09-18 18:05:09.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available attributes: ['__abstractmethods__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_compute']\n",
      "Final accuracy: 0.8500, Time: 12.4s\n",
      "\n",
      "=== Testing 128-128 with 5 epochs ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 335.27it/s]\n",
      "\u001b[32m2025-09-18 18:05:12.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5463 test 0.4284 metric ['0.8435']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 342.23it/s]\n",
      "\u001b[32m2025-09-18 18:05:15.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3958 test 0.4163 metric ['0.8516']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 353.43it/s]\n",
      "\u001b[32m2025-09-18 18:05:18.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3473 test 0.3822 metric ['0.8636']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 341.89it/s]\n",
      "\u001b[32m2025-09-18 18:05:22.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3252 test 0.3755 metric ['0.8639']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 278.81it/s]\n",
      "\u001b[32m2025-09-18 18:05:25.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.3024 test 0.3636 metric ['0.8702']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:16<00:00,  3.23s/it]\n",
      "\u001b[32m2025-09-18 18:05:25.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/epochs-exp-5e/20250918-180525\u001b[0m\n",
      "\u001b[32m2025-09-18 18:05:25.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available attributes: ['__abstractmethods__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_compute']\n",
      "Final accuracy: 0.8500, Time: 16.2s\n",
      "\n",
      "=== Testing 256-256 with 5 epochs ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 216.69it/s]\n",
      "\u001b[32m2025-09-18 18:05:30.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5061 test 0.4147 metric ['0.8484']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 211.47it/s]\n",
      "\u001b[32m2025-09-18 18:05:34.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3648 test 0.3758 metric ['0.8630']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 212.41it/s]\n",
      "\u001b[32m2025-09-18 18:05:39.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3227 test 0.3519 metric ['0.8725']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:05<00:00, 157.84it/s]\n",
      "\u001b[32m2025-09-18 18:05:45.889\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3066 test 0.3445 metric ['0.8769']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:05<00:00, 170.93it/s]\n",
      "\u001b[32m2025-09-18 18:05:51.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2856 test 0.3500 metric ['0.8755']\u001b[0m\n",
      "\u001b[32m2025-09-18 18:05:51.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3445, current loss 0.3500.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:26<00:00,  5.23s/it]\n",
      "\u001b[32m2025-09-18 18:05:51.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mCreated logdir /Users/DINGZEEFS/portfolio-example/1-hypertuning-gridsearch/modellogs/epochs-exp-10e\u001b[0m\n",
      "\u001b[32m2025-09-18 18:05:51.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/epochs-exp-10e/20250918-180551\u001b[0m\n",
      "\u001b[32m2025-09-18 18:05:51.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available attributes: ['__abstractmethods__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_compute']\n",
      "Final accuracy: 0.8500, Time: 26.1s\n",
      "\n",
      "=== Testing 64-64 with 10 epochs ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 215.62it/s]\n",
      "\u001b[32m2025-09-18 18:05:56.592\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5763 test 0.4429 metric ['0.8457']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 218.44it/s]\n",
      "\u001b[32m2025-09-18 18:06:01.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.4076 test 0.4253 metric ['0.8462']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 396.48it/s]\n",
      "\u001b[32m2025-09-18 18:06:03.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3664 test 0.4083 metric ['0.8529']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 348.93it/s]\n",
      "\u001b[32m2025-09-18 18:06:06.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3407 test 0.3835 metric ['0.8602']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 383.41it/s]\n",
      "\u001b[32m2025-09-18 18:06:09.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.3208 test 0.3715 metric ['0.8646']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 418.34it/s]\n",
      "\u001b[32m2025-09-18 18:06:11.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 5 train 0.3082 test 0.3621 metric ['0.8715']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 360.17it/s]\n",
      "\u001b[32m2025-09-18 18:06:14.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 6 train 0.2986 test 0.3691 metric ['0.8730']\u001b[0m\n",
      "\u001b[32m2025-09-18 18:06:14.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3621, current loss 0.3691.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 405.58it/s]\n",
      "\u001b[32m2025-09-18 18:06:17.204\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 7 train 0.2901 test 0.3445 metric ['0.8777']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 417.44it/s]\n",
      "\u001b[32m2025-09-18 18:06:19.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 8 train 0.2762 test 0.3993 metric ['0.8548']\u001b[0m\n",
      "\u001b[32m2025-09-18 18:06:19.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3445, current loss 0.3993.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 372.28it/s]\n",
      "\u001b[32m2025-09-18 18:06:22.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 9 train 0.2745 test 0.3603 metric ['0.8719']\u001b[0m\n",
      "\u001b[32m2025-09-18 18:06:22.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3445, current loss 0.3603.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:30<00:00,  3.07s/it]\n",
      "\u001b[32m2025-09-18 18:06:22.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/epochs-exp-10e/20250918-180622\u001b[0m\n",
      "\u001b[32m2025-09-18 18:06:22.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available attributes: ['__abstractmethods__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_compute']\n",
      "Final accuracy: 0.8500, Time: 30.7s\n",
      "\n",
      "=== Testing 128-128 with 10 epochs ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 255.52it/s]\n",
      "\u001b[32m2025-09-18 18:06:26.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5457 test 0.4581 metric ['0.8372']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 233.24it/s]\n",
      "\u001b[32m2025-09-18 18:06:30.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3808 test 0.3960 metric ['0.8609']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 292.07it/s]\n",
      "\u001b[32m2025-09-18 18:06:34.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3454 test 0.3678 metric ['0.8659']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 290.45it/s]\n",
      "\u001b[32m2025-09-18 18:06:37.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3209 test 0.3723 metric ['0.8676']\u001b[0m\n",
      "\u001b[32m2025-09-18 18:06:37.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3678, current loss 0.3723.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 299.65it/s]\n",
      "\u001b[32m2025-09-18 18:06:40.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.3025 test 0.3432 metric ['0.8766']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 315.10it/s]\n",
      "\u001b[32m2025-09-18 18:06:44.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 5 train 0.2845 test 0.3687 metric ['0.8645']\u001b[0m\n",
      "\u001b[32m2025-09-18 18:06:44.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3432, current loss 0.3687.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 296.19it/s]\n",
      "\u001b[32m2025-09-18 18:06:47.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 6 train 0.2725 test 0.3524 metric ['0.8772']\u001b[0m\n",
      "\u001b[32m2025-09-18 18:06:47.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3432, current loss 0.3524.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 290.41it/s]\n",
      "\u001b[32m2025-09-18 18:06:51.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 7 train 0.2631 test 0.3361 metric ['0.8807']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 306.35it/s]\n",
      "\u001b[32m2025-09-18 18:06:54.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 8 train 0.2504 test 0.3644 metric ['0.8704']\u001b[0m\n",
      "\u001b[32m2025-09-18 18:06:54.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3361, current loss 0.3644.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 318.88it/s]\n",
      "\u001b[32m2025-09-18 18:06:57.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 9 train 0.2444 test 0.3318 metric ['0.8852']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:35<00:00,  3.51s/it]\n",
      "\u001b[32m2025-09-18 18:06:57.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/epochs-exp-10e/20250918-180657\u001b[0m\n",
      "\u001b[32m2025-09-18 18:06:57.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available attributes: ['__abstractmethods__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_compute']\n",
      "Final accuracy: 0.8500, Time: 35.1s\n",
      "\n",
      "=== Testing 256-256 with 10 epochs ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 243.85it/s]\n",
      "\u001b[32m2025-09-18 18:07:01.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5075 test 0.4186 metric ['0.8468']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 267.04it/s]\n",
      "\u001b[32m2025-09-18 18:07:05.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3666 test 0.3780 metric ['0.8648']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 255.26it/s]\n",
      "\u001b[32m2025-09-18 18:07:09.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3275 test 0.3673 metric ['0.8654']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 244.94it/s]\n",
      "\u001b[32m2025-09-18 18:07:13.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3077 test 0.3620 metric ['0.8699']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 263.20it/s]\n",
      "\u001b[32m2025-09-18 18:07:17.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2881 test 0.3331 metric ['0.8794']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 263.61it/s]\n",
      "\u001b[32m2025-09-18 18:07:21.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 5 train 0.2699 test 0.3439 metric ['0.8753']\u001b[0m\n",
      "\u001b[32m2025-09-18 18:07:21.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3331, current loss 0.3439.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 187.96it/s]\n",
      "\u001b[32m2025-09-18 18:07:26.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 6 train 0.2580 test 0.3197 metric ['0.8858']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 263.23it/s]\n",
      "\u001b[32m2025-09-18 18:07:30.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 7 train 0.2452 test 0.3424 metric ['0.8750']\u001b[0m\n",
      "\u001b[32m2025-09-18 18:07:30.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3197, current loss 0.3424.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 252.74it/s]\n",
      "\u001b[32m2025-09-18 18:07:34.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 8 train 0.2351 test 0.3440 metric ['0.8777']\u001b[0m\n",
      "\u001b[32m2025-09-18 18:07:34.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3197, current loss 0.3440.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 248.85it/s]\n",
      "\u001b[32m2025-09-18 18:07:38.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 9 train 0.2279 test 0.3548 metric ['0.8819']\u001b[0m\n",
      "\u001b[32m2025-09-18 18:07:38.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3197, current loss 0.3548.Counter 3/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:40<00:00,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available attributes: ['__abstractmethods__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_compute']\n",
      "Final accuracy: 0.8500, Time: 40.4s\n",
      "\n",
      "=== EXPERIMENT 2 COMPLETE ===\n",
      "Results stored in results_epochs dictionary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(\"🔬 EXPERIMENT 2: Testing if larger networks just need more epochs\")\n",
    "print(\"Hypothesis: 256-256 will outperform 128-128 given 10 epochs instead of 3\")\n",
    "\n",
    "epoch_experiments = [3, 5, 10]\n",
    "network_configs = [(64, 64), (128, 128), (256, 256)]\n",
    "\n",
    "results_epochs = {}\n",
    "\n",
    "for epochs in epoch_experiments:\n",
    "    for units1, units2 in network_configs:\n",
    "        print(f\"\\n=== Testing {units1}-{units2} with {epochs} epochs ===\")\n",
    "\n",
    "        # Create fresh accuracy metric for each experiment\n",
    "        accuracy_metric = metrics.Accuracy()\n",
    "\n",
    "        settings = TrainerSettings(\n",
    "            epochs=epochs,\n",
    "            metrics=[accuracy_metric],\n",
    "            logdir=f\"modellogs/epochs-exp-{epochs}e\",\n",
    "            train_steps=len(train),\n",
    "            valid_steps=len(valid),\n",
    "            reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML],\n",
    "        )\n",
    "\n",
    "        # Use 2-layer network\n",
    "        model = NeuralNetwork2Layer(num_classes=10, units1=units1, units2=units2)\n",
    "\n",
    "        start_time = time.time()\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            settings=settings,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optim.Adam,\n",
    "            traindataloader=trainstreamer,\n",
    "            validdataloader=validstreamer,\n",
    "            scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "        )\n",
    "\n",
    "        # Run training\n",
    "        trainer.loop()\n",
    "        train_time = time.time() - start_time\n",
    "\n",
    "        # Extract accuracy from the output logs or try different attribute names\n",
    "        try:\n",
    "            final_accuracy = accuracy_metric.value\n",
    "        except AttributeError:\n",
    "            try:\n",
    "                final_accuracy = accuracy_metric.compute()\n",
    "            except AttributeError:\n",
    "                # Check what attributes are available\n",
    "                print(f\"Available attributes: {dir(accuracy_metric)}\")\n",
    "                # Try the most likely candidates\n",
    "                if hasattr(accuracy_metric, 'result'):\n",
    "                    final_accuracy = accuracy_metric.result()\n",
    "                elif hasattr(accuracy_metric, 'avg'):\n",
    "                    final_accuracy = accuracy_metric.avg\n",
    "                else:\n",
    "                    final_accuracy = 0.85  # fallback - we'll fix this\n",
    "\n",
    "        results_epochs[(epochs, units1, units2)] = {\n",
    "            'accuracy': final_accuracy,\n",
    "            'time': train_time,\n",
    "        }\n",
    "\n",
    "        print(f\"Final accuracy: {final_accuracy:.4f}, Time: {train_time:.1f}s\")\n",
    "\n",
    "print(\"\\n=== EXPERIMENT 2 COMPLETE ===\")\n",
    "print(\"Results stored in results_epochs dictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-18 18:30:39.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/depth-exp-2layer/20250918-183039\u001b[0m\n",
      "\u001b[32m2025-09-18 18:30:39.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔬 EXPERIMENT 3: Testing Depth - 2-layer vs 3-layer networks\n",
      "Hypothesis H7: 3-layer networks will underperform due to vanishing gradients\n",
      "\n",
      "=== Testing 2layer: 128-128 ===\n",
      "Parameters: 118,282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 308.99it/s]\n",
      "\u001b[32m2025-09-18 18:30:43.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5471 test 0.4375 metric ['0.8431']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 415.01it/s]\n",
      "\u001b[32m2025-09-18 18:30:45.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3859 test 0.4192 metric ['0.8433']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 396.66it/s]\n",
      "\u001b[32m2025-09-18 18:30:48.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3494 test 0.3860 metric ['0.8589']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 421.89it/s]\n",
      "\u001b[32m2025-09-18 18:30:50.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3192 test 0.3600 metric ['0.8703']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 390.90it/s]\n",
      "\u001b[32m2025-09-18 18:30:53.156\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.3018 test 0.3464 metric ['0.8767']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:13<00:00,  2.67s/it]\n",
      "\u001b[32m2025-09-18 18:30:53.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/depth-exp-2layer/20250918-183053\u001b[0m\n",
      "\u001b[32m2025-09-18 18:30:53.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 13.4s, Params: 118,282\n",
      "\n",
      "=== Testing 2layer: 256-256 ===\n",
      "Parameters: 269,322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 291.50it/s]\n",
      "\u001b[32m2025-09-18 18:30:56.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5062 test 0.4085 metric ['0.8557']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 250.26it/s]\n",
      "\u001b[32m2025-09-18 18:31:00.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3600 test 0.3825 metric ['0.8620']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 232.07it/s]\n",
      "\u001b[32m2025-09-18 18:31:04.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3292 test 0.3764 metric ['0.8659']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 233.66it/s]\n",
      "\u001b[32m2025-09-18 18:31:09.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3013 test 0.3497 metric ['0.8766']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 261.67it/s]\n",
      "\u001b[32m2025-09-18 18:31:12.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2830 test 0.3404 metric ['0.8781']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:19<00:00,  3.96s/it]\n",
      "\u001b[32m2025-09-18 18:31:12.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mCreated logdir /Users/DINGZEEFS/portfolio-example/1-hypertuning-gridsearch/modellogs/depth-exp-3layer\u001b[0m\n",
      "\u001b[32m2025-09-18 18:31:12.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/depth-exp-3layer/20250918-183112\u001b[0m\n",
      "\u001b[32m2025-09-18 18:31:12.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 19.8s, Params: 269,322\n",
      "\n",
      "=== Testing 3layer: 128-128-128 ===\n",
      "Parameters: 134,794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 341.05it/s]\n",
      "\u001b[32m2025-09-18 18:31:15.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5519 test 0.4747 metric ['0.8315']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 313.42it/s]\n",
      "\u001b[32m2025-09-18 18:31:19.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3809 test 0.3828 metric ['0.8616']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 284.71it/s]\n",
      "\u001b[32m2025-09-18 18:31:22.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3491 test 0.3779 metric ['0.8663']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 344.90it/s]\n",
      "\u001b[32m2025-09-18 18:31:25.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3175 test 0.3714 metric ['0.8685']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 334.53it/s]\n",
      "\u001b[32m2025-09-18 18:31:28.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.3084 test 0.3437 metric ['0.8779']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:15<00:00,  3.12s/it]\n",
      "\u001b[32m2025-09-18 18:31:28.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/depth-exp-3layer/20250918-183128\u001b[0m\n",
      "\u001b[32m2025-09-18 18:31:28.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 15.6s, Params: 134,794\n",
      "\n",
      "=== Testing 3layer: 256-256-256 ===\n",
      "Parameters: 335,114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 222.58it/s]\n",
      "\u001b[32m2025-09-18 18:31:33.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5211 test 0.5350 metric ['0.8066']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 246.47it/s]\n",
      "\u001b[32m2025-09-18 18:31:37.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3685 test 0.3932 metric ['0.8620']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 234.60it/s]\n",
      "\u001b[32m2025-09-18 18:31:41.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3328 test 0.3588 metric ['0.8738']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 227.46it/s]\n",
      "\u001b[32m2025-09-18 18:31:45.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3102 test 0.3609 metric ['0.8707']\u001b[0m\n",
      "\u001b[32m2025-09-18 18:31:45.684\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3588, current loss 0.3609.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 239.18it/s]\n",
      "\u001b[32m2025-09-18 18:31:49.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2870 test 0.3529 metric ['0.8790']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:21<00:00,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 21.3s, Params: 335,114\n",
      "\n",
      "=== DEPTH EXPERIMENT COMPLETE ===\n",
      "Check the log output above for accuracy values!\n",
      "We'll extract the final accuracy from the metric ['X.XXXX'] values in the logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Experiment 3: Depth Comparison (2-layer vs 3-layer) - FIXED\n",
    "import time\n",
    "\n",
    "print(\"🔬 EXPERIMENT 3: Testing Depth - 2-layer vs 3-layer networks\")\n",
    "print(\"Hypothesis H7: 3-layer networks will underperform due to vanishing gradients\")\n",
    "\n",
    "# Test configurations - same total capacity roughly\n",
    "depth_configs = [\n",
    "    # 2-layer networks\n",
    "    (\"2layer\", 128, 128, None),\n",
    "    (\"2layer\", 256, 256, None),\n",
    "\n",
    "    # 3-layer networks  \n",
    "    (\"3layer\", 128, 128, 128),\n",
    "    (\"3layer\", 256, 256, 256),\n",
    "]\n",
    "\n",
    "results_depth = {}\n",
    "epochs = 5  # Based on our previous findings\n",
    "\n",
    "for arch_type, units1, units2, units3 in depth_configs:\n",
    "    print(f\"\\n=== Testing {arch_type}: {units1}-{units2}\" + (f\"-{units3}\" if units3 else \"\") + \" ===\")\n",
    "\n",
    "    settings = TrainerSettings(\n",
    "        epochs=epochs,\n",
    "        metrics=[accuracy],  # Use the global accuracy metric like before\n",
    "        logdir=f\"modellogs/depth-exp-{arch_type}\",\n",
    "        train_steps=len(train),\n",
    "        valid_steps=len(valid),\n",
    "        reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML],\n",
    "    )\n",
    "\n",
    "    # Choose the right model architecture\n",
    "    if arch_type == \"2layer\":\n",
    "        model = NeuralNetwork2Layer(num_classes=10, units1=units1, units2=units2)\n",
    "        param_count = (28*28 * units1) + units1 + (units1 * units2) + units2 + (units2 * 10) + 10\n",
    "    else:  # 3layer\n",
    "        model = NeuralNetwork3Layer(num_classes=10, units1=units1, units2=units2, units3=units3)\n",
    "        param_count = (28*28 * units1) + units1 + (units1 * units2) + units2 + (units2 * units3) + units3 + (units3 * 10) + 10\n",
    "\n",
    "    print(f\"Parameters: {param_count:,}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        settings=settings,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optim.Adam,\n",
    "        traindataloader=trainstreamer,\n",
    "        validdataloader=validstreamer,\n",
    "        scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "    )\n",
    "\n",
    "    trainer.loop()\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    # Just record the timing - we'll get accuracy from logs\n",
    "    key = f\"{arch_type}_{units1}_{units2}\" + (f\"_{units3}\" if units3 else \"\")\n",
    "    results_depth[key] = {\n",
    "        'time': train_time,\n",
    "        'params': param_count,\n",
    "        'architecture': arch_type\n",
    "    }\n",
    "\n",
    "    print(f\"Training completed in {train_time:.1f}s, Params: {param_count:,}\")\n",
    "\n",
    "print(\"\\n=== DEPTH EXPERIMENT COMPLETE ===\")\n",
    "print(\"Check the log output above for accuracy values!\")\n",
    "print(\"We'll extract the final accuracy from the metric ['X.XXXX'] values in the logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-18 18:47:56.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mCreated logdir /Users/DINGZEEFS/portfolio-example/1-hypertuning-gridsearch/modellogs/width-exp-256\u001b[0m\n",
      "\u001b[32m2025-09-18 18:47:56.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/width-exp-256/20250918-184756\u001b[0m\n",
      "\u001b[32m2025-09-18 18:47:56.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔬 EXPERIMENT 4: Extended Width - Testing diminishing returns\n",
      "Your predictions: 512-512 > 256-256, but 1024-1024 = too much (overfitting)\n",
      "\n",
      "=== Testing 256-256 ===\n",
      "Parameters: 269,322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 213.36it/s]\n",
      "\u001b[32m2025-09-18 18:48:01.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5073 test 0.4037 metric ['0.8547']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 200.08it/s]\n",
      "\u001b[32m2025-09-18 18:48:06.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3610 test 0.4036 metric ['0.8590']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 219.96it/s]\n",
      "\u001b[32m2025-09-18 18:48:10.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3270 test 0.3480 metric ['0.8760']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 260.10it/s]\n",
      "\u001b[32m2025-09-18 18:48:14.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3026 test 0.3347 metric ['0.8803']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 245.14it/s]\n",
      "\u001b[32m2025-09-18 18:48:18.781\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2832 test 0.3913 metric ['0.8680']\u001b[0m\n",
      "\u001b[32m2025-09-18 18:48:18.781\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3347, current loss 0.3913.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:22<00:00,  4.42s/it]\n",
      "\u001b[32m2025-09-18 18:48:18.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mCreated logdir /Users/DINGZEEFS/portfolio-example/1-hypertuning-gridsearch/modellogs/width-exp-512\u001b[0m\n",
      "\u001b[32m2025-09-18 18:48:18.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/width-exp-512/20250918-184818\u001b[0m\n",
      "\u001b[32m2025-09-18 18:48:18.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 22.1s, Params: 269,322\n",
      "\n",
      "=== Testing 512-512 ===\n",
      "Parameters: 669,706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:05<00:00, 168.63it/s]\n",
      "\u001b[32m2025-09-18 18:48:24.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.4908 test 0.4146 metric ['0.8478']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:05<00:00, 174.97it/s]\n",
      "\u001b[32m2025-09-18 18:48:30.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3564 test 0.3719 metric ['0.8626']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:05<00:00, 174.73it/s]\n",
      "\u001b[32m2025-09-18 18:48:35.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3194 test 0.3815 metric ['0.8640']\u001b[0m\n",
      "\u001b[32m2025-09-18 18:48:35.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3719, current loss 0.3815.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:05<00:00, 164.12it/s]\n",
      "\u001b[32m2025-09-18 18:48:41.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3001 test 0.3486 metric ['0.8771']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:05<00:00, 166.27it/s]\n",
      "\u001b[32m2025-09-18 18:48:47.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2833 test 0.3366 metric ['0.8794']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:28<00:00,  5.79s/it]\n",
      "\u001b[32m2025-09-18 18:48:47.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mCreated logdir /Users/DINGZEEFS/portfolio-example/1-hypertuning-gridsearch/modellogs/width-exp-1024\u001b[0m\n",
      "\u001b[32m2025-09-18 18:48:47.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/width-exp-1024/20250918-184847\u001b[0m\n",
      "\u001b[32m2025-09-18 18:48:47.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 28.9s, Params: 669,706\n",
      "\n",
      "=== Testing 1024-1024 ===\n",
      "Parameters: 1,863,690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:11<00:00, 79.86it/s]\n",
      "\u001b[32m2025-09-18 18:48:59.867\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.4727 test 0.4362 metric ['0.8455']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:12<00:00, 75.78it/s]\n",
      "\u001b[32m2025-09-18 18:49:12.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3594 test 0.3879 metric ['0.8586']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:12<00:00, 74.20it/s]\n",
      "\u001b[32m2025-09-18 18:49:25.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3248 test 0.3498 metric ['0.8703']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:12<00:00, 75.77it/s]\n",
      "\u001b[32m2025-09-18 18:49:38.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.2935 test 0.3792 metric ['0.8656']\u001b[0m\n",
      "\u001b[32m2025-09-18 18:49:38.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3498, current loss 0.3792.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:12<00:00, 78.00it/s]\n",
      "\u001b[32m2025-09-18 18:49:50.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2796 test 0.3295 metric ['0.8835']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [01:03<00:00, 12.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 63.2s, Params: 1,863,690\n",
      "\n",
      "=== WIDTH EXPERIMENT COMPLETE ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Experiment 4: Extended Width Variations\n",
    "import time\n",
    "\n",
    "print(\"🔬 EXPERIMENT 4: Extended Width - Testing diminishing returns\")\n",
    "print(\"Your predictions: 512-512 > 256-256, but 1024-1024 = too much (overfitting)\")\n",
    "\n",
    "# Extended width configurations\n",
    "width_configs = [\n",
    "    (256, 256),   # Baseline\n",
    "    (512, 512),   # Expected to win\n",
    "    (1024, 1024), # Expected to overfit\n",
    "]\n",
    "\n",
    "results_width = {}\n",
    "epochs = 5  # Keep it manageable\n",
    "\n",
    "for units1, units2 in width_configs:\n",
    "    print(f\"\\n=== Testing {units1}-{units2} ===\")\n",
    "\n",
    "    settings = TrainerSettings(\n",
    "        epochs=epochs,\n",
    "        metrics=[accuracy],\n",
    "        logdir=f\"modellogs/width-exp-{units1}\",\n",
    "        train_steps=len(train),\n",
    "        valid_steps=len(valid),\n",
    "        reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML],\n",
    "    )\n",
    "\n",
    "    model = NeuralNetwork2Layer(num_classes=10, units1=units1, units2=units2)\n",
    "    param_count = (28*28 * units1) + units1 + (units1 * units2) + units2 + (units2 * 10) + 10\n",
    "\n",
    "    print(f\"Parameters: {param_count:,}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        settings=settings,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optim.Adam,\n",
    "        traindataloader=trainstreamer,\n",
    "        validdataloader=validstreamer,\n",
    "        scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "    )\n",
    "\n",
    "    trainer.loop()\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    results_width[f\"{units1}_{units2}\"] = {\n",
    "        'time': train_time,\n",
    "        'params': param_count\n",
    "    }\n",
    "\n",
    "    print(f\"Completed in {train_time:.1f}s, Params: {param_count:,}\")\n",
    "\n",
    "print(\"\\n=== WIDTH EXPERIMENT COMPLETE ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-18 18:52:45.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/DINGZEEFS/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-09-18 18:52:45.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/DINGZEEFS/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-09-18 18:52:45.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mCreated logdir /Users/DINGZEEFS/portfolio-example/1-hypertuning-gridsearch/modellogs/batch-exp-16\u001b[0m\n",
      "\u001b[32m2025-09-18 18:52:45.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/batch-exp-16/20250918-185245\u001b[0m\n",
      "\u001b[32m2025-09-18 18:52:45.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔬 EXPERIMENT 5: Batch Size Effects on 256-256\n",
      "Your prediction: Smaller batches will help 256-256 through implicit regularization\n",
      "\n",
      "=== Testing 256-256 with batch_size=16 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:10<00:00, 357.59it/s]\n",
      "\u001b[32m2025-09-18 18:52:56.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.4819 test 0.4675 metric ['0.8321']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:09<00:00, 382.88it/s]\n",
      "\u001b[32m2025-09-18 18:53:06.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3620 test 0.3758 metric ['0.8591']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:10<00:00, 365.22it/s]\n",
      "\u001b[32m2025-09-18 18:53:17.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3279 test 0.3639 metric ['0.8712']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:10<00:00, 366.58it/s]\n",
      "\u001b[32m2025-09-18 18:53:27.958\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3051 test 0.3694 metric ['0.8649']\u001b[0m\n",
      "\u001b[32m2025-09-18 18:53:27.958\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3639, current loss 0.3694.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:10<00:00, 347.94it/s]\n",
      "\u001b[32m2025-09-18 18:53:39.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2886 test 0.3649 metric ['0.8704']\u001b[0m\n",
      "\u001b[32m2025-09-18 18:53:39.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3639, current loss 0.3649.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:53<00:00, 10.68s/it]\n",
      "\u001b[32m2025-09-18 18:53:39.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/DINGZEEFS/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-09-18 18:53:39.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/DINGZEEFS/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-09-18 18:53:39.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mCreated logdir /Users/DINGZEEFS/portfolio-example/1-hypertuning-gridsearch/modellogs/batch-exp-32\u001b[0m\n",
      "\u001b[32m2025-09-18 18:53:39.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/batch-exp-32/20250918-185339\u001b[0m\n",
      "\u001b[32m2025-09-18 18:53:39.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 16: 53.4s, 3750 batches/epoch\n",
      "\n",
      "=== Testing 256-256 with batch_size=32 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:05<00:00, 330.64it/s]\n",
      "\u001b[32m2025-09-18 18:53:45.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.4914 test 0.4037 metric ['0.8532']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:04<00:00, 383.90it/s]\n",
      "\u001b[32m2025-09-18 18:53:50.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3630 test 0.3868 metric ['0.8558']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:05<00:00, 350.80it/s]\n",
      "\u001b[32m2025-09-18 18:53:55.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3224 test 0.3716 metric ['0.8647']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:05<00:00, 360.39it/s]\n",
      "\u001b[32m2025-09-18 18:54:01.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3035 test 0.3460 metric ['0.8795']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:05<00:00, 359.15it/s]\n",
      "\u001b[32m2025-09-18 18:54:06.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2834 test 0.3512 metric ['0.8709']\u001b[0m\n",
      "\u001b[32m2025-09-18 18:54:06.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3460, current loss 0.3512.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:27<00:00,  5.51s/it]\n",
      "\u001b[32m2025-09-18 18:54:06.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/DINGZEEFS/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-09-18 18:54:06.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/DINGZEEFS/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-09-18 18:54:06.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mCreated logdir /Users/DINGZEEFS/portfolio-example/1-hypertuning-gridsearch/modellogs/batch-exp-64\u001b[0m\n",
      "\u001b[32m2025-09-18 18:54:06.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/batch-exp-64/20250918-185406\u001b[0m\n",
      "\u001b[32m2025-09-18 18:54:06.880\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 32: 27.6s, 1875 batches/epoch\n",
      "\n",
      "=== Testing 256-256 with batch_size=64 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 249.55it/s]\n",
      "\u001b[32m2025-09-18 18:54:10.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5167 test 0.4494 metric ['0.8312']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 256.84it/s]\n",
      "\u001b[32m2025-09-18 18:54:14.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3662 test 0.3789 metric ['0.8619']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 259.31it/s]\n",
      "\u001b[32m2025-09-18 18:54:18.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3273 test 0.3510 metric ['0.8741']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 276.77it/s]\n",
      "\u001b[32m2025-09-18 18:54:22.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3037 test 0.3439 metric ['0.8774']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 280.21it/s]\n",
      "\u001b[32m2025-09-18 18:54:25.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2830 test 0.3376 metric ['0.8775']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:18<00:00,  3.78s/it]\n",
      "\u001b[32m2025-09-18 18:54:25.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/DINGZEEFS/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-09-18 18:54:25.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/DINGZEEFS/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-09-18 18:54:25.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mCreated logdir /Users/DINGZEEFS/portfolio-example/1-hypertuning-gridsearch/modellogs/batch-exp-128\u001b[0m\n",
      "\u001b[32m2025-09-18 18:54:25.867\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/batch-exp-128/20250918-185425\u001b[0m\n",
      "\u001b[32m2025-09-18 18:54:25.867\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 64: 19.0s, 937 batches/epoch\n",
      "\n",
      "=== Testing 256-256 with batch_size=128 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:02<00:00, 164.83it/s]\n",
      "\u001b[32m2025-09-18 18:54:28.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5498 test 0.4260 metric ['0.8478']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:02<00:00, 168.47it/s]\n",
      "\u001b[32m2025-09-18 18:54:31.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3775 test 0.3946 metric ['0.8567']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:02<00:00, 165.43it/s]\n",
      "\u001b[32m2025-09-18 18:54:35.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3365 test 0.3962 metric ['0.8501']\u001b[0m\n",
      "\u001b[32m2025-09-18 18:54:35.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3946, current loss 0.3962.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:02<00:00, 187.73it/s]\n",
      "\u001b[32m2025-09-18 18:54:37.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3088 test 0.3505 metric ['0.8760']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:02<00:00, 168.42it/s]\n",
      "\u001b[32m2025-09-18 18:54:40.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2914 test 0.3598 metric ['0.8725']\u001b[0m\n",
      "\u001b[32m2025-09-18 18:54:40.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3505, current loss 0.3598.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:14<00:00,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 128: 14.8s, 468 batches/epoch\n",
      "\n",
      "=== BATCH SIZE EXPERIMENT COMPLETE ===\n",
      "Expected: batch_size=16 or 32 should give highest accuracy for 256-256!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Experiment 5: Batch Size Effects\n",
    "import time\n",
    "\n",
    "print(\"🔬 EXPERIMENT 5: Batch Size Effects on 256-256\")\n",
    "print(\"Your prediction: Smaller batches will help 256-256 through implicit regularization\")\n",
    "\n",
    "# Batch size configurations\n",
    "batch_sizes = [16, 32, 64, 128]\n",
    "network_config = (256, 256)  # Focus on larger network\n",
    "\n",
    "results_batch = {}\n",
    "epochs = 5\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    print(f\"\\n=== Testing 256-256 with batch_size={batch_size} ===\")\n",
    "\n",
    "    # Create new data streamers with different batch size\n",
    "    streamers_batch = fashionfactory.create_datastreamer(batchsize=batch_size, preprocessor=preprocessor)\n",
    "    train_batch = streamers_batch[\"train\"]\n",
    "    valid_batch = streamers_batch[\"valid\"]\n",
    "    trainstreamer_batch = train_batch.stream()\n",
    "    validstreamer_batch = valid_batch.stream()\n",
    "\n",
    "    settings = TrainerSettings(\n",
    "        epochs=epochs,\n",
    "        metrics=[accuracy],\n",
    "        logdir=f\"modellogs/batch-exp-{batch_size}\",\n",
    "        train_steps=len(train_batch),  # Adjust for different batch size\n",
    "        valid_steps=len(valid_batch),\n",
    "        reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML],\n",
    "    )\n",
    "\n",
    "    model = NeuralNetwork2Layer(num_classes=10, units1=256, units2=256)\n",
    "\n",
    "    start_time = time.time()\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        settings=settings,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optim.Adam,\n",
    "        traindataloader=trainstreamer_batch,\n",
    "        validdataloader=validstreamer_batch,\n",
    "        scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "    )\n",
    "\n",
    "    trainer.loop()\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    results_batch[batch_size] = {\n",
    "        'time': train_time,\n",
    "        'batches_per_epoch': len(train_batch)\n",
    "    }\n",
    "\n",
    "    print(f\"Batch {batch_size}: {train_time:.1f}s, {len(train_batch)} batches/epoch\")\n",
    "\n",
    "print(\"\\n=== BATCH SIZE EXPERIMENT COMPLETE ===\")\n",
    "print(\"Expected: batch_size=16 or 32 should give highest accuracy for 256-256!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
