{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercises \n",
    "# 1. Tune the network\n",
    "Run the experiment below, explore the different parameters (see suggestions below) and study the result with tensorboard. \n",
    "Make a single page (1 a4) report of your findings. Use your visualisation skills to communicate your most important findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "from mltrainer import imagemodels, Trainer, TrainerSettings, ReportTypes, metrics\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from tomlserializer import TOMLSerializer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using `tomlserializer` to easily keep track of our experiments, and to easily save the different things we did during our experiments.\n",
    "It can export things like settings and models to a simple `toml` file, which can be easily shared, checked and modified.\n",
    "\n",
    "First, we need the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-15 15:16:54.656\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mStart download...\u001b[0m\n",
      "  0%|\u001b[38;2;30;71;6m          \u001b[0m| 0.00/55.4M [00:00<?, ?iB/s]\u001b[32m2025-09-15 15:16:56.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.datatools\u001b[0m:\u001b[36mget_file\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mDownloading /Users/DINGZEEFS/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 55.4M/55.4M [00:02<00:00, 19.8MiB/s]\n",
      "\u001b[32m2025-09-15 15:16:59.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m112\u001b[0m - \u001b[1mDigest of /Users/DINGZEEFS/.cache/mads_datasets/fashionmnist/fashionmnist.pt matches expected digest\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "fashionfactory = DatasetFactoryProvider.create_factory(DatasetType.FASHION)\n",
    "preprocessor = BasePreprocessor()\n",
    "streamers = fashionfactory.create_datastreamer(batchsize=64, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]\n",
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a way to determine how well our model is performing. We will use accuracy as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can set up a single experiment.\n",
    "\n",
    "- We will show the model batches of 64 images, \n",
    "- and for every epoch we will show the model 100 batches (trainsteps=100).\n",
    "- then, we will test how well the model is doing on unseen data (teststeps=100).\n",
    "- we will report our results during training to tensorboard, and report all configuration to a toml file.\n",
    "- we will log the results into a directory called \"modellogs\", but you could change this to whatever you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-15 15:19:08.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mCreated logdir /Users/DINGZEEFS/portfolio-example/1-hypertuning-gridsearch/modellogs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=3,\n",
    "    metrics=[accuracy],\n",
    "    logdir=\"modellogs\",\n",
    "    train_steps=100,\n",
    "    valid_steps=100,\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a very basic model: a model with three linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_classes: int, units1: int, units2: int) -> None:\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.units1 = units1\n",
    "        self.units2 = units2\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, units1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units1, units2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units2, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork(\n",
    "    num_classes=10, units1=256, units2=256)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I developped the `tomlserializer` package, it is a useful tool to save configs, models and settings as a tomlfile; that way it is easy to track what you changed during your experiments.\n",
    "\n",
    "This package will 1. check if there is a `__dict__` attribute available, and if so, it will use that to extract the parameters that do not start with an underscore, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True, 'num_classes': 10, 'units1': 256, 'units2': 256}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v for k, v in model.__dict__.items() if not k.startswith(\"_\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that if you want to add more parameters to the `.toml` file, eg `units3`, you can add them to the class like this:\n",
    "\n",
    "```python\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_classes: int, units1: int, units2: int, units3: int) -> None:\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.units1 = units1\n",
    "        self.units2 = units2\n",
    "        self.units3 = units3  # <-- add this line\n",
    "```\n",
    "\n",
    "And then it will be added to the `.toml` file. Check the result for yourself by using the `.save()` method of the `TomlSerializer` class like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomlserializer = TOMLSerializer()\n",
    "tomlserializer.save(settings, \"settings.toml\")\n",
    "tomlserializer.save(model, \"model.toml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the `settings.toml` and `model.toml` files to see what is in there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `Trainer` class from my `mltrainer` module to train your model. It has the TOMLserializer integrated, so it will automatically save the settings and model to a toml file if you have added `TOML` as a reporttype in the settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-15 15:20:22.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250915-152022\u001b[0m\n",
      "\u001b[32m2025-09-15 15:20:27.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 207.46it/s]\n",
      "\u001b[32m2025-09-15 15:20:28.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.9242 test 0.6378 metric ['0.7769']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 273.16it/s]\n",
      "\u001b[32m2025-09-15 15:20:28.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.5572 test 0.6043 metric ['0.7777']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 271.92it/s]\n",
      "\u001b[32m2025-09-15 15:20:29.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.5088 test 0.5114 metric ['0.8194']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:01<00:00,  1.70it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optim.Adam,\n",
    "    traindataloader=trainstreamer,\n",
    "    validdataloader=validstreamer,\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    ")\n",
    "trainer.loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, check in the modellogs directory the results of your experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now loop this with a naive approach, called a grid-search (why do you think i call it naive?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Units: 256, 256\n",
      "Units: 256, 128\n",
      "Units: 256, 64\n",
      "Units: 128, 256\n",
      "Units: 128, 128\n",
      "Units: 128, 64\n",
      "Units: 64, 256\n",
      "Units: 64, 128\n",
      "Units: 64, 64\n"
     ]
    }
   ],
   "source": [
    "units = [256, 128, 64]\n",
    "for unit1 in units:\n",
    "    for unit2 in units:\n",
    "        print(f\"Units: {unit1}, {unit2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, this might not be the best way to search for a model; some configurations will be better than others (can you predict up front what will be the best configuration?).\n",
    "\n",
    "So, feel free to improve upon the gridsearch by adding your own logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-15 15:21:12.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250915-152112\u001b[0m\n",
      "\u001b[32m2025-09-15 15:21:12.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 209.36it/s]\n",
      "\u001b[32m2025-09-15 15:21:17.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5121 test 0.4368 metric ['0.8434']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 208.42it/s]\n",
      "\u001b[32m2025-09-15 15:21:22.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3665 test 0.3936 metric ['0.8555']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:07<00:00, 132.14it/s]\n",
      "\u001b[32m2025-09-15 15:21:29.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3237 test 0.3562 metric ['0.8724']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:17<00:00,  5.78s/it]\n",
      "\u001b[32m2025-09-15 15:21:29.960\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250915-152129\u001b[0m\n",
      "\u001b[32m2025-09-15 15:21:29.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 204.71it/s]\n",
      "\u001b[32m2025-09-15 15:21:34.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5330 test 0.4266 metric ['0.8462']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 262.00it/s]\n",
      "\u001b[32m2025-09-15 15:21:38.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3748 test 0.3829 metric ['0.8633']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 233.77it/s]\n",
      "\u001b[32m2025-09-15 15:21:43.029\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3327 test 0.3713 metric ['0.8664']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:13<00:00,  4.36s/it]\n",
      "\u001b[32m2025-09-15 15:21:43.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250915-152143\u001b[0m\n",
      "\u001b[32m2025-09-15 15:21:43.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 232.32it/s]\n",
      "\u001b[32m2025-09-15 15:21:47.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5391 test 0.4481 metric ['0.8422']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 264.06it/s]\n",
      "\u001b[32m2025-09-15 15:21:51.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3855 test 0.4031 metric ['0.8512']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 256.93it/s]\n",
      "\u001b[32m2025-09-15 15:21:55.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3386 test 0.3713 metric ['0.8697']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:12<00:00,  4.06s/it]\n",
      "\u001b[32m2025-09-15 15:21:55.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250915-152155\u001b[0m\n",
      "\u001b[32m2025-09-15 15:21:55.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 273.52it/s]\n",
      "\u001b[32m2025-09-15 15:21:58.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5260 test 0.4414 metric ['0.8362']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 313.33it/s]\n",
      "\u001b[32m2025-09-15 15:22:02.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3701 test 0.3937 metric ['0.8619']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 321.33it/s]\n",
      "\u001b[32m2025-09-15 15:22:05.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3326 test 0.4111 metric ['0.8515']\u001b[0m\n",
      "\u001b[32m2025-09-15 15:22:05.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3937, current loss 0.4111.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:10<00:00,  3.39s/it]\n",
      "\u001b[32m2025-09-15 15:22:05.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250915-152205\u001b[0m\n",
      "\u001b[32m2025-09-15 15:22:05.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 339.54it/s]\n",
      "\u001b[32m2025-09-15 15:22:08.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5412 test 0.4791 metric ['0.8264']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 349.67it/s]\n",
      "\u001b[32m2025-09-15 15:22:11.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3812 test 0.3910 metric ['0.8582']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 351.56it/s]\n",
      "\u001b[32m2025-09-15 15:22:14.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3398 test 0.3631 metric ['0.8678']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:08<00:00,  2.99s/it]\n",
      "\u001b[32m2025-09-15 15:22:14.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250915-152214\u001b[0m\n",
      "\u001b[32m2025-09-15 15:22:14.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 342.48it/s]\n",
      "\u001b[32m2025-09-15 15:22:17.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5552 test 0.4400 metric ['0.8462']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 339.97it/s]\n",
      "\u001b[32m2025-09-15 15:22:20.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3953 test 0.4333 metric ['0.8412']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 265.29it/s]\n",
      "\u001b[32m2025-09-15 15:22:24.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3506 test 0.3756 metric ['0.8636']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:09<00:00,  3.29s/it]\n",
      "\u001b[32m2025-09-15 15:22:24.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250915-152224\u001b[0m\n",
      "\u001b[32m2025-09-15 15:22:24.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 279.25it/s]\n",
      "\u001b[32m2025-09-15 15:22:27.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5424 test 0.4344 metric ['0.8415']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 277.90it/s]\n",
      "\u001b[32m2025-09-15 15:22:31.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3885 test 0.3942 metric ['0.8592']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 292.09it/s]\n",
      "\u001b[32m2025-09-15 15:22:35.028\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3459 test 0.3767 metric ['0.8632']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:10<00:00,  3.60s/it]\n",
      "\u001b[32m2025-09-15 15:22:35.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250915-152235\u001b[0m\n",
      "\u001b[32m2025-09-15 15:22:35.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 310.36it/s]\n",
      "\u001b[32m2025-09-15 15:22:38.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5645 test 0.4561 metric ['0.8370']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 308.98it/s]\n",
      "\u001b[32m2025-09-15 15:22:41.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3988 test 0.4031 metric ['0.8510']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 302.14it/s]\n",
      "\u001b[32m2025-09-15 15:22:45.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3538 test 0.3882 metric ['0.8589']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:10<00:00,  3.42s/it]\n",
      "\u001b[32m2025-09-15 15:22:45.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250915-152245\u001b[0m\n",
      "\u001b[32m2025-09-15 15:22:45.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 321.46it/s]\n",
      "\u001b[32m2025-09-15 15:22:48.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5854 test 0.4632 metric ['0.8384']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 334.70it/s]\n",
      "\u001b[32m2025-09-15 15:22:51.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.4058 test 0.4127 metric ['0.8535']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 369.13it/s]\n",
      "\u001b[32m2025-09-15 15:22:54.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3649 test 0.3869 metric ['0.8610']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:09<00:00,  3.01s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "units = [256, 128, 64]\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=3,\n",
    "    metrics=[accuracy],\n",
    "    logdir=\"modellogs\",\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML],\n",
    ")\n",
    "\n",
    "for unit1 in units:\n",
    "    for unit2 in units:\n",
    "\n",
    "        model = NeuralNetwork(num_classes=10, units1=unit1, units2=unit2)\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            settings=settings,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optim.Adam,\n",
    "            traindataloader=trainstreamer,\n",
    "            validdataloader=validstreamer,\n",
    "            scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "        )\n",
    "        trainer.loop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have set the ReportType to TOML, you will find in every log dir a model.toml and settings.toml file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment, and study the result with tensorboard. \n",
    "\n",
    "Locally, it is easy to do that with VS code itself. On the server, you have to take these steps:\n",
    "\n",
    "- in the terminal, `cd` to the location of the repository\n",
    "- activate the python environment for the shell. Note how the correct environment is being activated.\n",
    "- run `tensorboard --logdir=modellogs` in the terminal\n",
    "- tensorboard will launch at `localhost:6006` and vscode will notify you that the port is forwarded\n",
    "- you can either press the `launch` button in VScode or open your local browser at `localhost:6006`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting by Liam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 — Units grid (hidden-layer width): what and why\n",
    "- **What are units?** Units are the number of neurons in a hidden layer (e.g., `units1`, `units2`). More units = higher model capacity.\n",
    "- **Why sweep them?** Capacity affects how much structure the model can learn. Too few → underfit; too many → may overfit.\n",
    "- **How we’ll compare fairly:** We’ll treat an epoch as the full dataset (`train_steps=len(train)`, `valid_steps=len(valid)`) so each epoch sees the same amount of data. We’ll keep everything else fixed and vary only the widths.\n",
    "- **What to watch in TensorBoard:**\n",
    "  - Training vs validation loss/accuracy.\n",
    "  - A widening train–valid gap suggests overfitting; both flat and low accuracy suggests underfitting.\n",
    "\n",
    "We’ll run a small grid: `units ∈ {64, 128, 256}` for both layers, log to `modellogs/units-grid-v1`, and make a heatmap of validation accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility: set a global seed\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers: run one experiment and compute validation accuracy directly\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "\n",
    "# We reuse accuracy metric, and use fresh streams for evaluation\n",
    "\n",
    "@dataclass\n",
    "class RunResult:\n",
    "    units1: int\n",
    "    units2: int\n",
    "    logdir: Path\n",
    "    val_acc: float\n",
    "\n",
    "\n",
    "def build_model(units1: int, units2: int) -> nn.Module:\n",
    "    model = NeuralNetwork(num_classes=10, units1=units1, units2=units2)\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_settings(base_logdir: str, epochs: int = 3) -> TrainerSettings:\n",
    "    return TrainerSettings(\n",
    "        epochs=epochs,\n",
    "        metrics=[accuracy],\n",
    "        logdir=base_logdir,\n",
    "        train_steps=len(train),\n",
    "        valid_steps=len(valid),\n",
    "        reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML],\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_validation_accuracy(model: nn.Module, steps: int | None = None) -> float:\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    vstream = valid.stream()\n",
    "    max_steps = steps or len(valid)\n",
    "    with torch.no_grad():\n",
    "        for step_idx, (xb, yb) in enumerate(vstream):\n",
    "            logits = model(xb)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "            if step_idx + 1 >= max_steps:\n",
    "                break\n",
    "    return correct / max_steps / (yb.size(0) if total == 0 else (total / max_steps)) if total > 0 else float(\"nan\")\n",
    "\n",
    "\n",
    "def run_single(units1: int, units2: int, base_logdir: str) -> RunResult:\n",
    "    set_seed(42)\n",
    "    model = build_model(units1, units2)\n",
    "    settings = build_settings(base_logdir=base_logdir, epochs=3)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        settings=settings,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optim.Adam,\n",
    "        traindataloader=trainstreamer,\n",
    "        validdataloader=validstreamer,\n",
    "        scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    )\n",
    "    trainer.loop()\n",
    "\n",
    "    # Trainer creates a timestamped subdir; find the latest in base_logdir\n",
    "    base = Path(settings.logdir)\n",
    "    latest = max((p for p in base.iterdir() if p.is_dir()), key=lambda p: p.stat().st_mtime)\n",
    "\n",
    "    # Compute validation accuracy directly\n",
    "    val_acc = compute_validation_accuracy(model, steps=len(valid))\n",
    "    return RunResult(units1=units1, units2=units2, logdir=latest, val_acc=val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-15 15:50:04.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/units-grid-v1/20250915-155004\u001b[0m\n",
      "\u001b[32m2025-09-15 15:50:04.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running units1=64, units2=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 353.07it/s]\n",
      "\u001b[32m2025-09-15 15:50:07.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5965 test 0.4818 metric ['0.8289']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 355.73it/s]\n",
      "\u001b[32m2025-09-15 15:50:10.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.4204 test 0.4536 metric ['0.8340']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 364.97it/s]\n",
      "\u001b[32m2025-09-15 15:50:13.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3776 test 0.4190 metric ['0.8498']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:08<00:00,  2.88s/it]\n",
      "\u001b[32m2025-09-15 15:50:13.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/units-grid-v1/20250915-155013\u001b[0m\n",
      "\u001b[32m2025-09-15 15:50:13.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running units1=64, units2=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 341.73it/s]\n",
      "\u001b[32m2025-09-15 15:50:16.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5766 test 0.4744 metric ['0.8306']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 352.22it/s]\n",
      "\u001b[32m2025-09-15 15:50:19.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.4068 test 0.4239 metric ['0.8445']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 367.48it/s]\n",
      "\u001b[32m2025-09-15 15:50:21.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3619 test 0.4083 metric ['0.8526']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:08<00:00,  2.91s/it]\n",
      "\u001b[32m2025-09-15 15:50:21.840\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/units-grid-v1/20250915-155021\u001b[0m\n",
      "\u001b[32m2025-09-15 15:50:21.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running units1=64, units2=256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 342.54it/s]\n",
      "\u001b[32m2025-09-15 15:50:24.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5470 test 0.4364 metric ['0.8428']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 279.14it/s]\n",
      "\u001b[32m2025-09-15 15:50:28.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3921 test 0.4071 metric ['0.8479']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 357.36it/s]\n",
      "\u001b[32m2025-09-15 15:50:31.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3528 test 0.4186 metric ['0.8476']\u001b[0m\n",
      "\u001b[32m2025-09-15 15:50:31.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.4071, current loss 0.4186.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:09<00:00,  3.17s/it]\n",
      "\u001b[32m2025-09-15 15:50:31.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/units-grid-v1/20250915-155031\u001b[0m\n",
      "\u001b[32m2025-09-15 15:50:31.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running units1=128, units2=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 325.77it/s]\n",
      "\u001b[32m2025-09-15 15:50:34.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5605 test 0.4473 metric ['0.8416']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 340.18it/s]\n",
      "\u001b[32m2025-09-15 15:50:37.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3944 test 0.4129 metric ['0.8482']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 337.55it/s]\n",
      "\u001b[32m2025-09-15 15:50:40.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3519 test 0.4114 metric ['0.8526']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:09<00:00,  3.06s/it]\n",
      "\u001b[32m2025-09-15 15:50:40.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/units-grid-v1/20250915-155040\u001b[0m\n",
      "\u001b[32m2025-09-15 15:50:40.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running units1=128, units2=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 339.51it/s]\n",
      "\u001b[32m2025-09-15 15:50:43.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5472 test 0.4330 metric ['0.8463']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 343.32it/s]\n",
      "\u001b[32m2025-09-15 15:50:46.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3869 test 0.4078 metric ['0.8520']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 329.87it/s]\n",
      "\u001b[32m2025-09-15 15:50:49.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3454 test 0.4002 metric ['0.8583']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:09<00:00,  3.04s/it]\n",
      "\u001b[32m2025-09-15 15:50:49.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/units-grid-v1/20250915-155049\u001b[0m\n",
      "\u001b[32m2025-09-15 15:50:49.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running units1=128, units2=256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 311.44it/s]\n",
      "\u001b[32m2025-09-15 15:50:52.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5237 test 0.4135 metric ['0.8535']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 336.08it/s]\n",
      "\u001b[32m2025-09-15 15:50:56.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3719 test 0.3924 metric ['0.8571']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 317.96it/s]\n",
      "\u001b[32m2025-09-15 15:50:59.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3326 test 0.3881 metric ['0.8598']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:09<00:00,  3.20s/it]\n",
      "\u001b[32m2025-09-15 15:50:59.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/units-grid-v1/20250915-155059\u001b[0m\n",
      "\u001b[32m2025-09-15 15:50:59.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running units1=256, units2=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 301.87it/s]\n",
      "\u001b[32m2025-09-15 15:51:02.656\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5379 test 0.4302 metric ['0.8456']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 294.25it/s]\n",
      "\u001b[32m2025-09-15 15:51:06.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3820 test 0.4016 metric ['0.8529']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 309.44it/s]\n",
      "\u001b[32m2025-09-15 15:51:09.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3413 test 0.3929 metric ['0.8573']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:10<00:00,  3.39s/it]\n",
      "\u001b[32m2025-09-15 15:51:09.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/units-grid-v1/20250915-155109\u001b[0m\n",
      "\u001b[32m2025-09-15 15:51:09.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running units1=256, units2=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 276.14it/s]\n",
      "\u001b[32m2025-09-15 15:51:13.156\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5235 test 0.4197 metric ['0.8512']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 278.09it/s]\n",
      "\u001b[32m2025-09-15 15:51:16.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3725 test 0.3941 metric ['0.8563']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 294.02it/s]\n",
      "\u001b[32m2025-09-15 15:51:20.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3341 test 0.4012 metric ['0.8550']\u001b[0m\n",
      "\u001b[32m2025-09-15 15:51:20.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3941, current loss 0.4012.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:10<00:00,  3.61s/it]\n",
      "\u001b[32m2025-09-15 15:51:20.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/units-grid-v1/20250915-155120\u001b[0m\n",
      "\u001b[32m2025-09-15 15:51:20.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running units1=256, units2=256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 278.08it/s]\n",
      "\u001b[32m2025-09-15 15:51:23.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5044 test 0.4128 metric ['0.8524']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 242.76it/s]\n",
      "\u001b[32m2025-09-15 15:51:28.091\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3648 test 0.3715 metric ['0.8636']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 230.62it/s]\n",
      "\u001b[32m2025-09-15 15:51:32.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3267 test 0.3808 metric ['0.8596']\u001b[0m\n",
      "\u001b[32m2025-09-15 15:51:32.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3715, current loss 0.3808.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:12<00:00,  4.05s/it]\n",
      "/Users/DINGZEEFS/portfolio-example/.venv/lib/python3.12/site-packages/seaborn/matrix.py:202: RuntimeWarning: All-NaN slice encountered\n",
      "  vmin = np.nanmin(calc_data)\n",
      "/Users/DINGZEEFS/portfolio-example/.venv/lib/python3.12/site-packages/seaborn/matrix.py:207: RuntimeWarning: All-NaN slice encountered\n",
      "  vmax = np.nanmax(calc_data)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run units1×units2 grid and build a small results table and heatmap\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "units = [64, 128, 256]\n",
    "base_logdir = \"modellogs/units-grid-v1\"\n",
    "Path(base_logdir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "results = []\n",
    "for u1, u2 in product(units, units):\n",
    "    print(f\"Running units1={u1}, units2={u2}\")\n",
    "    rr = run_single(u1, u2, base_logdir)\n",
    "    val_acc = rr.val_acc\n",
    "    results.append({\"units1\": u1, \"units2\": u2, \"val_acc\": val_acc, \"run_dir\": str(rr.logdir)})\n",
    "\n",
    "# Results table\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n",
    "\n",
    "# Heatmap\n",
    "pivot = results_df.pivot(index=\"units1\", columns=\"units2\", values=\"val_acc\")\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(pivot, annot=True, fmt=\".3f\", cmap=\"viridis\")\n",
    "plt.title(\"Validation accuracy by units1 × units2\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
